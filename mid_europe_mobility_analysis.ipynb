{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Mobility Analysis Of Austria, Belgium & Germany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good Practices In Constructing Time Series\n",
    "\n",
    "In any craft there are basic principles with which one must learn in order to lay the foundation of good work. Time series visualisation is no different, relying on many important decisions by the data scientist before coming to fruition.\n",
    "\n",
    "We can trace a history of these graphs back to Scottish economist William Playfair. Playfair combined his love of art and data to create the graph we now know as a time series. His first publication in 1786 looks incredibly modern, plotting the cost of wheat against the cost of labour in England. His graph disproved a hypthesis that wages were driving the price of wheat up. Playfair showed that they were actually rising much slower than the price of wheat with this very clever display, rising a new dawn for data visualisations of time periods.\n",
    "\n",
    "![Playfair's First Time Series](res/playfair_time_series.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we introduce time into a graph, it gives rise to many distinct components. \n",
    "Common components of a time series include:\n",
    "* **Trend** - The general tendency to increase or decrease over time.\n",
    "\n",
    "* **Seasonality** - Peaks / troughs that occur at regular intervals. This can be daily, weekly, monthly or even yearly cycles.\n",
    "\n",
    "* **Noise** - Random fluctuations in data which are left when all the components have been removed.\n",
    "\n",
    "In constructing our time series, we will pay respect to each of these components. Seasonality can be tested using statistical tests, while trends are more random. Noise occurs in any real-world data set, and can be dealt with through methods such as smoothing and resampling. We will be constructing time series both with smoothing/resampling and without, in order to gain a complete picture of the data. The aim is to show what the data means, rather than merely what it looks like plotted.\n",
    "\n",
    "I have decided to use three different types of visualisations to display each attribute. I believe that these four visualisations will give us a strong sense of the magnitude of change in our data and intuitively represent these changes for analysis.\n",
    "\n",
    "### Universal Line Plot\n",
    "This plot will contain our original data and represents a starting point for our understanding. This is the root of the visualisations to come, as it will give us the clearest picture of the trends, seasonality and noise within our dataset. \n",
    "\n",
    "Additionally, annotations will be added to this plot in order to mark key moments related to the attribute. These may give us insight into particular peaks or troughs in relation to that specific attribute.\n",
    "\n",
    "### Density Plot W/ Moving Average Smoothing\n",
    "My aim with this density plot is to give us much more of a feel into the major changes that occurred during the time period. A moving average smoothing technique will be applied in order to remove the effect of outliers on the data and filter out noise. \n",
    "\n",
    "### Resampled Bar W/ Differencing\n",
    "This graph will apply differencing, where the data represents the change from one day to the next. We can set the window of change so that it will tell us the difference between as large a gap as we would like. Resampling will be applied to our bar chart to give it a \"more\" discrete visualisation and reduce the amount of bins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structuring Our Code\n",
    "When visualising the data, we don't want to write the same block of code repeatedly in order to get different results. We want to quickly move from attribute to attribute without having to worry to much about the underlying code.\n",
    "\n",
    "To ensure we can focus on the visualisations, I'm going to set up a class that will give us the above plots for each attribute as simply as we would like. This overlying class I'm going to call the \"Mobility Suite\". This suite will use plotly, pandas and numpy in order to give us the results that we need from the data.\n",
    "\n",
    "There are different aspects to this suite such as:\n",
    "* **Mobility Manager** - Loads the data from CSV files.\n",
    "* **Graph** - Basic parent class to create a graph.\n",
    "    * **Transformer** - Performs Resampling, Smoothing & Differencing\n",
    "    * **Visualisations**:\n",
    "        * **Visualisation 1**: Universal Line Plot \n",
    "        * **Visualisation 2**: Density Plot W/ Rolling Mean\n",
    "        * **Visualisation 3**: Resampled Bar W/ Differencing\n",
    "        \n",
    "#### Standardising Calls To Country/Attribute\n",
    "Additionally, we will standardise our call to each attribute and country.\n",
    "Rather than ever using a string to call to an attribute or country, which may only work by coincedence of us using the string correctly, we will use enums. \n",
    "    \n",
    "![Mobility Suite](./res/mobility_suite_structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Mobility Manager\n",
    "We'll begin by setting up the class to load in our data. It acts as the intermediary between the programmer and the data, ensuring we don't run into any problems in our interactions. \n",
    "\n",
    "Firstly, let's create two enums to reference each Country and attribute in our data. We will use the enum class for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "\n",
    "class Country(enum.IntEnum):\n",
    "\tBelgium = 0,\n",
    "\tGermany = 1,\n",
    "\tAustria = 2\n",
    "\n",
    "class Attribute(enum.IntEnum):\n",
    "\tID = 0,\n",
    "\tCountry = 1,\n",
    "\tDate = 2,\n",
    "\tRetail_And_Rec = 3,\n",
    "\tGrocery_And_Pharma = 4,\n",
    "\tParks = 5,\n",
    "\tTransit = 6,\n",
    "\tWorkplaces = 7,\n",
    "\tResidential = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will write the implementation for our Mobility Manager. Rather than write a markdown paragraph for each part, I will include python comments that will make clear what I'm creating at each different section. The most useful method, as we will see, will be the **get_attribute** call, which will be extremely useful for loading particular elements of our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class MobilityManager:\n",
    "\n",
    "\t#Our CSV Files\n",
    "\taustria_file = \"austria.csv\"\n",
    "\tbelgium_file = \"belgium.csv\"\n",
    "\tgermany_file = \"germany.csv\"\n",
    "\n",
    "\t\"\"\"\n",
    "\tIn order to be able to use the standardised \n",
    "\tattribute enum we created, we will need a dictionary to \n",
    "\tconvert from these attribute enums to the column \n",
    "\tname thatwe need from the dataframe.\n",
    "\n",
    "\tFor our Countries, we'll store each dataframe itself \n",
    "\tinside the dict as this is simpler.\n",
    "\n",
    "\tTLDR:\n",
    "\tDicts Convert \n",
    "\t(Attribute Enum) => (Column String)\n",
    "\t(Country Enum) => (Country DataFrame)\n",
    "\t\"\"\"\n",
    "\tattribute_converter = {}\n",
    "\tcountry_converter = {}\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\t#Load Our Dataset From CSV File\n",
    "\t\taustria_set = self.load_dataset(self.austria_file)\n",
    "\t\tbelgium_set = self.load_dataset(self.belgium_file)\n",
    "\t\tgermany_set = self.load_dataset(self.germany_file)\n",
    "\n",
    "\t\t#Store Our Dataset In Dict With Enums\n",
    "\t\tself.country_converter[Country.Austria] = austria_set\n",
    "\t\tself.country_converter[Country.Belgium] = belgium_set\n",
    "\t\tself.country_converter[Country.Germany] = germany_set\n",
    "\n",
    "\t\t#Store Our Attributes in Dict\n",
    "\t\tattributes = austria_set.columns\n",
    "\t\tfor att_id, att_str in zip(Attribute, attributes):\n",
    "\t\t\tself.attribute_converter[str(att_id)] = att_str\n",
    "\n",
    "\t#Load In A Dataset From CSV File\n",
    "\tdef load_dataset(self, f):\n",
    "\t\treturn pd.read_csv(\"./datasets/{}\".format(f))\n",
    "\n",
    "\t#Get A Saved Dataset\n",
    "\tdef get_set(self, country):\n",
    "\t\treturn self.country_sets[country]\n",
    "\n",
    "\t#Get Attribute Data For A Particular Country\n",
    "\tdef get_attribute(self, country, attribute):\n",
    "\t\tatt_str = self.attributes[str(attribute)]\n",
    "\t\treturn self.get_set(country)[att_str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Transformer\n",
    "I've named the next class like so due to the manipulations it performs on the data. This class will perform three very important steps for us:\n",
    "* Smoothing (Rolling Average)\n",
    "* Resampling\n",
    "* Differencing\n",
    "\n",
    "These will be used in various amounts in our visualisations in order to present the clearest picture of what the data is telling us rather than the clearest picture of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer:\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\treturn\n",
    "\n",
    "\t#Combines Two Series/Attributes Into One Dataframe\n",
    "\tdef _combine(self, A, B, name_A, name_B):\n",
    "\t\t#Combine Name With Series\n",
    "\t\tdf = { \n",
    "\t\tname_A : A, \n",
    "\t\tname_B : B\n",
    "\t\t}\n",
    "\n",
    "\t\t#Concatenate These Series Into Dataset\n",
    "\t\treturn  pd.concat(df,axis=1)\n",
    "\n",
    "\t#Performs Differencing\n",
    "\tdef get_difference(self, y, periods):\n",
    "\t\treturn y.diff(periods=periods)\n",
    "\n",
    "\t#Performs Smoothing\n",
    "\tdef get_rolling_mean(self, dates, y, windows):\n",
    "\t\t#Combine Our Dates & Target Series\n",
    "\t\trolling_df = self._combine(dates, y, 'date', 'target')\n",
    "\n",
    "\t\t#Create Rolling Mean On Target Attribute\n",
    "\t\trolling_mean = rolling_df['target'].rolling(\n",
    "\t\t\twindow=windows).mean()\n",
    "\t\treturn dates, rolling_mean\n",
    "\n",
    "\t#Performs Resampling\n",
    "\tdef get_resample(self, dates, y, rule):\n",
    "\t\t#Combine Our Dates & Target Series\n",
    "\t\tdf = self._combine(dates, y, 'date', 'target')\n",
    "\n",
    "\t\t#Convert to correct format and set as string\n",
    "\t\tdf['date'] = pd.to_datetime(df.date, format='%Y-%m-%d')\n",
    "\t\tdf = df.set_index('date')\n",
    "\n",
    "\t\t#Resample our data\n",
    "\t\tresample = df.target.resample(rule).mean()\n",
    "\t\treturn resample.index, resample.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Class & Visualisations\n",
    "The crux of our visualisations will lie with plotly and its excellent plotting library. We can see the structure of this part of our mobility suite below.\n",
    "\n",
    "* Graph Parent Class:\n",
    "    * Visualisation 1: Universal Line Plot \n",
    "    * Visualisation 2: Density Plot W/ Rolling Mean\n",
    "    * Visualisation 3: Resampled Bar W/ Differencing\n",
    "    \n",
    "When we put this all together, we aim to have all three plots as subplots in a figure. This will form a very elegant and informative picture of any given attribute in any given Country. \n",
    "\n",
    "Firstly, let's set up a very basic graph parent class. This will serve to create a transformer for use by any of our plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "\ttransformer = Transformer()\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\treturn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not the most complex code we have seen. However, it's good to create a backbone for our more specific plotting classes. \n",
    "\n",
    "### Universal Line Plot\n",
    "This line plot serves to show us our original data. There will be no transformations applied to this data as we want to keep it completely in line (excuse the pun..) with its original form.\n",
    "\n",
    "At this point I must mention a very important point that will be relevant for every graph that our suite will create. These graphs are in the context of the pandemic that has swept our world, and thus we see huge declines in most if not all of the attributes. This means that if we plotted the data exactly as it is, all of our graphs would move underneath the x axis and look a bit, well, upside down.\n",
    "\n",
    "To reconcile this, I've chosen to make each graph represent the decline in an attribute rather than the increase. Every data point will be multiplied by negative 1, thus higher numbers will mean greater decline. I believe this serves to improve the viewers understanding by not throwing them off with graphs that look strange. \n",
    "\n",
    "We can see below our code for this Line Plot, which inherits from our previous Graph class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "class LinePlot(Graph):\n",
    "\tdef plot(self, dates, target):\n",
    "\t\t#Represent The Decline In An Attribute\n",
    "\t\tdecrease_target = np.multiply(target,-1)\n",
    "\n",
    "\t\t#Create Line Plot\n",
    "\t\tline = go.Scatter(x=dates,y=decrease_target)\n",
    "\t\treturn line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density Plot\n",
    "Our density plot will be more complex than our previous plot. It will apply smoothing to the data by using a rolling mean. A rolling mean will separate our data into windows and calculate the mean along these windows to represent any given date. The larger our window, the greater the effort needed to change the data from any given period to the next. This will give us a better sense of the significance of change, rather than the confusion that noise and outliers often cause in the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DensityPlot(Graph):\n",
    "\tdef plot(self, dates, target, windows):\n",
    "\t\t#Represent Decline \n",
    "\t\ttarget = np.multiply(target,-1)\n",
    "\n",
    "\t\t#Retrieve Rolling Mean\n",
    "\t\tdates, roll_mean = super().transformer.get_rolling_mean(dates, \n",
    "\t\t\ttarget, windows)\n",
    "\n",
    "\t\t#Ensure Density Is Filled In\n",
    "\t\tfill = 'tozeroy'\n",
    "\t\treturn go.Scatter(x=dates,y=decrease_roll_mean, fill=fill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampled Bar W/ Differencing\n",
    "Differencing is the crux of why this graph will be so useful. Given a particular time span, it will tell us the difference from time period A to time period B. This should show us when the biggest falls due to the pandemic were and the biggest climbs back up. Our data will be flipped again, so that the bigger the fall the higher the value. \n",
    "\n",
    "Additionally, we will apply resampling to this data so that we can have the average for each month rather than working with each day. We will have 8 bins for the 8 months in our data. This is much better than plotting each individual day, and will give us a broader perspective. We will call this class a Resampled Bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResampledBar(Graph):\n",
    "\tdef plot(self, country, attribute, rule):\n",
    "\t\t#Flip The Values\n",
    "\t\ttarget = np.multiply(target,-1)\n",
    "\n",
    "\t\t#Apply Resampling\n",
    "\t\tdates, target = super().transformer.get_resample(country, \n",
    "\t\t\tattribute, rule)\n",
    "\n",
    "\t\t#Create The Bar Graph\n",
    "\t\tbar = go.Bar(x=dates, y=decrease_target)\n",
    "\t\treturn bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Mobility Suite\n",
    "We have now created all the individual elements of our mobility suite. The work we have done thus far really pays off here, as we will be able to easily create new graphs for various Countries and attributes.\n",
    "\n",
    "The **plot** function will really carry the weight of our visualisations and will relieve us of worrying about the programming details when analysing the graphs. Our interface for working with the data and visualising it has been completed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobilitySuite:\n",
    "\n",
    "\t#Number Of Rows/Cols Of Subplots\n",
    "\tsubplot_rows = None\n",
    "\tsubplot_cols = None\n",
    "\n",
    "\tfigure = None\n",
    "\n",
    "\t#Mobility Manager Created\n",
    "\tdata_manager = MobilityManager()\n",
    "\n",
    "\tdef __init__(self, rows, cols):\n",
    "\t\t#Create Subplots\n",
    "\t\tself.figure = make_subplots(rows = rows, \n",
    "\t\tcols = cols)\n",
    "\n",
    "\t\tself.subplot_rows = rows\n",
    "\t\tself.subplot_cols = cols\n",
    "\n",
    "\t\"\"\"\n",
    "\tThis plotting function below is the powerhouse of our \n",
    "\tsuite. It combines everything we have worked on thus\n",
    "\tfar into one function.\n",
    "\t\"\"\"\n",
    "\tdef plot(self, country, attribute, density_windows,\n",
    "\t\tresampling_bar_rule):\n",
    "\t\t#Retrieve Our Data\n",
    "\t\tdates = self.data_manager.get_attribute(\n",
    "\t\t\tcountry, Attribute.Date)\n",
    "\t\ttarget = self.data_manager.get_attribute(\n",
    "\t\t\tcountry, attribute)\n",
    "\n",
    "\t\t#Create A Line Graph\n",
    "\t\tgraph_line = self.get_plot_line(country, attribute)\n",
    "\n",
    "\t\t#Create A Density Graph\n",
    "\t\tgraph_density = self.get_plot_density(country, \n",
    "\t\t\tattribute, density_windows)\n",
    "\n",
    "\t\t#Create A Bar Graph\n",
    "\t\tgraph_bar = self.get_plot_resampled_bar(country,\n",
    "\t\t\tattribute, resampling_bar_rule)\n",
    "\n",
    "\t\t#Add These Plots As Subplots\n",
    "\t\tself.add_plots([graph_line, graph_density, graph_bar])\n",
    "\n",
    "    #Call To Lineplot Class\n",
    "\tdef get_plot_line(self, dates, target): \n",
    "\t\tgraph_line = LinePlot()\n",
    "\t\treturn graph_line.plot(dates, target)\n",
    "\n",
    "    #Call To Density Plot Class\n",
    "\tdef get_plot_density(self, dates, target, windows):\n",
    "\t\tgraph_density = DensityPlot()\n",
    "\t\treturn graph_density.plot(dates, target, windows)\n",
    "\n",
    "    #Call To Resampled Bar Class\n",
    "\tdef get_plot_resampled_bar(self, dates, target, rule):\n",
    "\t\tgraph_resampled_bar = ResampledBar()\n",
    "\t\treturn graph_resampled_bar.plot(dates, target, rule)\n",
    "\n",
    "\t#Add A List Of Subplots\n",
    "\tdef add_plots(self, plots):\n",
    "\t\tfor i in range(0, self.subplot_rows):\n",
    "\t\t\tnxt_plot = plots[i]\n",
    "\n",
    "\t\t\tself.figure.add_trace(nxt_plot, \n",
    "\t\t\t\trow=i+1, col=1)\n",
    "\n",
    "\t#Show The Graph\n",
    "\tdef show(self):\n",
    "\t\tself.figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
